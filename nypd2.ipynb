{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYPD Allegations\n",
    "* **See the main project notebook for instructions to be sure you satisfy the rubric!**\n",
    "* See Project 03 for information on the dataset.\n",
    "* A few example prediction questions to pursue are listed below. However, don't limit yourself to them!\n",
    "    * Predict the outcome of an allegation (might need to feature engineer your output column).\n",
    "    * Predict the complainant or officer ethnicity.\n",
    "    * Predict the amount of time between the month received vs month closed (difference of the two columns).\n",
    "    * Predict the rank of the officer.\n",
    "\n",
    "Be careful to justify what information you would know at the \"time of prediction\" and train your model using only those features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Findings\n",
    "\n",
    "\n",
    "### Introduction\n",
    "In this finding, we will be continue to study on the NYPD data set. More specifically, we will be using machine learning modeling to make predictions on NYPD officer's ranking during incident based on various predictors. \n",
    "\n",
    "### Baseline Model\n",
    "To start off the research, we will be performing data cleaning and selection on needed data. Cleaning method will inherit from the previoud project by filling in missing values and filtering out ``\"NaN\"`` values. After cleaning the data, we will be conducting a base logistic model using the ``Sklean`` package, and ``Pipeline`` that helps fitting and transforming the data into our logistic regression model. \n",
    "\n",
    "- Predictor ``\"mos_ethnicity\"`` is used as the baseline model to predict the officer's rankin. It seems intuitively that there is a relationship between officer's ethnicity and its title. Some ethnicity seems to have a higher general ranking than the others, and that is also the reason why we choose to start of the prediction using the ``\"mos_ethnicity\"`` variable. \n",
    "\n",
    "- We know that ``\"mos_ethnicity\"`` is an ordinal variable by discovering that it consist various ethnicities such as ``Hispanic``, ``White``, ``Black``, ``Asian``. To catergorize this predictor, we decide to use ``OrdinalEncoder`` to encode the difference in ethnicity, and by fitting it into a pipeline and logistic regression model, we obtained a ``68%`` of accuracy of our model and a ``0.6834`` R-squared value for this baseline model.\n",
    "\n",
    "Note: R-squared is a goodness-of-fit measure for linear regression models. It is valued between 0 to 1, the closer the number is getting to 1, means that the better the model is predicted. \n",
    "\n",
    "### Final Model\n",
    "Although our baseline model has a pretty good prediction on the officer's ranking. We would like to further investigate and want to improve the performance of the prediction. We designed to include feature engineering and predictor searching into different modeling and found the best model for our final model by using the ``\"mos_ethnicity\",\"mos_gender\", \"mos_age_incident\",\"rank_now\"`` variables. In addition to ``\"mos_ethnicity\"``, the final(best) model has three additional features that strongly helped to predict the officer's title. In the process of searching a related predictor manually by adding new features one by one, and later resulted our final model. \n",
    "\n",
    "- To fit the predictors into the pipeline, we first transform the column ``\"mos_age_incident\"`` into standardscaler, then apply one-hot-encoder to ``\"mos_gender\"`` and ordinal encoder to the columns ``\"mos_ethnicity\"`` and ``\"rank_now\"``. \n",
    "\n",
    "- ``\"mos_gender\"`` are categorized by ``\"M\"`` and ``\"F\"``. One-hot encoder will be the most appropreate to the transformation.\n",
    "\n",
    "- ``\"rank_now\"`` consist different ranking titles, and therfore it is being categorize as ``\"mos_ethnicity\"`` in above for the same reason. \n",
    "\n",
    "After fitting the predictors into our final model, we obtained a ``71%`` on the model accuracy. By all that means is that we are ``71%`` confident to correctly predict the officer's ranking at the indident given the ``\"mos_ethnicity\",\"mos_gender\", \"mos_age_incident\",\"rank_now\"`` predictors. Also, this model gives a ``0.7076`` R-squared value. It is so far the best predicted model that we obtained. \n",
    "\n",
    "\n",
    "### Fairness Evaluation\n",
    "Lastly, we will be assessing the model through a fairness evaluation, we will be splitting our data and uses permutation to conduct this study. We set a test size to ``0.3`` and a ``42`` random state in our splitting so that our data can be shuffled and draw more randomly for the assessment. The observing predictors will remains the same as our final model. \n",
    "\n",
    "- After splitting, we obtained ``X_train, X_test, y_train, y_test`` and ready to fit the data into our modeling.\n",
    "\n",
    "- We fit the ``X_train`` data into the final model pipeline and obtain a predicted train value, same for the ``X_test`` data. \n",
    "\n",
    "- After fitting the two modeling, we can see from the classification report that the two model are having the same accuracy of ``71%``. However, the f1-score on the ``X_train`` set peforms slightly better. Note: The F1 score is the harmonic average of the precision and recall, where an F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0. (Cited from Wikipedia)\n",
    "\n",
    "- Since the two models are obtaining a similar accuracy score and f1-score, we can say that we have a decent low false positives and low false negatives, and a true postive and true negative prediction.  Therefore, we can say that this model is pretty fair.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'  # Higher resolution figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loade the data\n",
    "df = pd.read_csv('allegations_202007271729.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the original data\n",
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_mos_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>command_now</th>\n",
       "      <th>shield_no</th>\n",
       "      <th>complaint_id</th>\n",
       "      <th>month_received</th>\n",
       "      <th>year_received</th>\n",
       "      <th>month_closed</th>\n",
       "      <th>year_closed</th>\n",
       "      <th>...</th>\n",
       "      <th>mos_age_incident</th>\n",
       "      <th>complainant_ethnicity</th>\n",
       "      <th>complainant_gender</th>\n",
       "      <th>complainant_age_incident</th>\n",
       "      <th>fado_type</th>\n",
       "      <th>allegation</th>\n",
       "      <th>precinct</th>\n",
       "      <th>contact_reason</th>\n",
       "      <th>outcome_description</th>\n",
       "      <th>board_disposition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10004</td>\n",
       "      <td>Jonathan</td>\n",
       "      <td>Ruiz</td>\n",
       "      <td>078 PCT</td>\n",
       "      <td>8409</td>\n",
       "      <td>42835</td>\n",
       "      <td>7</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>2020</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Abuse of Authority</td>\n",
       "      <td>Failure to provide RTKA card</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Report-domestic dispute</td>\n",
       "      <td>No arrest made or summons issued</td>\n",
       "      <td>Substantiated (Command Lvl Instructions)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10007</td>\n",
       "      <td>John</td>\n",
       "      <td>Sears</td>\n",
       "      <td>078 PCT</td>\n",
       "      <td>5952</td>\n",
       "      <td>24601</td>\n",
       "      <td>11</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>2012</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Discourtesy</td>\n",
       "      <td>Action</td>\n",
       "      <td>67.0</td>\n",
       "      <td>Moving violation</td>\n",
       "      <td>Moving violation summons issued</td>\n",
       "      <td>Substantiated (Charges)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10007</td>\n",
       "      <td>John</td>\n",
       "      <td>Sears</td>\n",
       "      <td>078 PCT</td>\n",
       "      <td>5952</td>\n",
       "      <td>24601</td>\n",
       "      <td>11</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>2012</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Offensive Language</td>\n",
       "      <td>Race</td>\n",
       "      <td>67.0</td>\n",
       "      <td>Moving violation</td>\n",
       "      <td>Moving violation summons issued</td>\n",
       "      <td>Substantiated (Charges)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10007</td>\n",
       "      <td>John</td>\n",
       "      <td>Sears</td>\n",
       "      <td>078 PCT</td>\n",
       "      <td>5952</td>\n",
       "      <td>26146</td>\n",
       "      <td>7</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Abuse of Authority</td>\n",
       "      <td>Question</td>\n",
       "      <td>67.0</td>\n",
       "      <td>PD suspected C/V of violation/crime - street</td>\n",
       "      <td>No arrest made or summons issued</td>\n",
       "      <td>Substantiated (Charges)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10009</td>\n",
       "      <td>Noemi</td>\n",
       "      <td>Sierra</td>\n",
       "      <td>078 PCT</td>\n",
       "      <td>24058</td>\n",
       "      <td>40253</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Force</td>\n",
       "      <td>Physical force</td>\n",
       "      <td>67.0</td>\n",
       "      <td>Report-dispute</td>\n",
       "      <td>Arrest - other violation/crime</td>\n",
       "      <td>Substantiated (Command Discipline A)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_mos_id first_name last_name command_now  shield_no  complaint_id  \\\n",
       "0          10004   Jonathan      Ruiz     078 PCT       8409         42835   \n",
       "1          10007       John     Sears     078 PCT       5952         24601   \n",
       "2          10007       John     Sears     078 PCT       5952         24601   \n",
       "3          10007       John     Sears     078 PCT       5952         26146   \n",
       "4          10009      Noemi    Sierra     078 PCT      24058         40253   \n",
       "\n",
       "   month_received  year_received  month_closed  year_closed  ...  \\\n",
       "0               7           2019             5         2020  ...   \n",
       "1              11           2011             8         2012  ...   \n",
       "2              11           2011             8         2012  ...   \n",
       "3               7           2012             9         2013  ...   \n",
       "4               8           2018             2         2019  ...   \n",
       "\n",
       "  mos_age_incident complainant_ethnicity complainant_gender  \\\n",
       "0               32                 Black             Female   \n",
       "1               24                 Black               Male   \n",
       "2               24                 Black               Male   \n",
       "3               25                 Black               Male   \n",
       "4               39                   NaN                NaN   \n",
       "\n",
       "  complainant_age_incident           fado_type                    allegation  \\\n",
       "0                     38.0  Abuse of Authority  Failure to provide RTKA card   \n",
       "1                     26.0         Discourtesy                        Action   \n",
       "2                     26.0  Offensive Language                          Race   \n",
       "3                     45.0  Abuse of Authority                      Question   \n",
       "4                     16.0               Force                Physical force   \n",
       "\n",
       "  precinct                                contact_reason  \\\n",
       "0     78.0                       Report-domestic dispute   \n",
       "1     67.0                              Moving violation   \n",
       "2     67.0                              Moving violation   \n",
       "3     67.0  PD suspected C/V of violation/crime - street   \n",
       "4     67.0                                Report-dispute   \n",
       "\n",
       "                outcome_description                         board_disposition  \n",
       "0  No arrest made or summons issued  Substantiated (Command Lvl Instructions)  \n",
       "1   Moving violation summons issued                   Substantiated (Charges)  \n",
       "2   Moving violation summons issued                   Substantiated (Charges)  \n",
       "3  No arrest made or summons issued                   Substantiated (Charges)  \n",
       "4    Arrest - other violation/crime      Substantiated (Command Discipline A)  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 5 entries of the data set\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning on needed to use columns\n",
    "\n",
    "data['Complaint_ethnicity'] = data['complainant_ethnicity'].replace({'Unknow': np.NaN, 'Refused':np.NaN})\n",
    "data['complainant_gender'] = data['complainant_gender'].replace({'Gender non-conforming': np.NaN, 'Not described': np.NaN, 'Transman(FTM)': 'Male', 'Transwoman (MTF)': 'Female'})\n",
    "data = data.drop_duplicates()\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing as pp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data[['mos_ethnicity']], data['rank_incident']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline for the transformation\n",
    "\n",
    "pl1 = Pipeline([\n",
    "    ('ord', OrdinalEncoder()),\n",
    "    ('log_reg', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linxi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ord', OrdinalEncoder()), ('log_reg', LogisticRegression())])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Police Officer', 'Police Officer', 'Police Officer', ...,\n",
       "       'Police Officer', 'Police Officer', 'Police Officer'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pl1.predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linxi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\linxi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "         Captain       0.00      0.00      0.00       109\n",
      "Deputy Inspector       0.00      0.00      0.00        75\n",
      "       Detective       0.00      0.00      0.00      2584\n",
      "       Inspector       0.00      0.00      0.00        23\n",
      "      Lieutenant       0.00      0.00      0.00      1018\n",
      "  Police Officer       0.68      1.00      0.81     18690\n",
      "        Sergeant       0.00      0.00      0.00      4849\n",
      "\n",
      "        accuracy                           0.68     27348\n",
      "       macro avg       0.10      0.14      0.12     27348\n",
      "    weighted avg       0.47      0.68      0.55     27348\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linxi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6834137779727951"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R^2 \n",
    "pl1.score(X, y) # Ok prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model Searching for a better model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linxi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\linxi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "         Captain       0.00      0.00      0.00       109\n",
      "Deputy Inspector       0.00      0.00      0.00        75\n",
      "       Detective       0.00      0.00      0.00      2584\n",
      "       Inspector       0.00      0.00      0.00        23\n",
      "      Lieutenant       0.00      0.00      0.00      1018\n",
      "  Police Officer       0.72      0.95      0.82     18690\n",
      "        Sergeant       0.29      0.17      0.21      4849\n",
      "\n",
      "        accuracy                           0.68     27348\n",
      "       macro avg       0.14      0.16      0.15     27348\n",
      "    weighted avg       0.54      0.68      0.60     27348\n",
      "\n",
      "0.6765759836185461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linxi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\linxi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X, y = data[['mos_gender','mos_age_incident']], data['rank_incident']\n",
    "# Numeric columns and associated transformers\n",
    "num_feat = ['mos_age_incident']\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('scaler', pp.StandardScaler())   # z-scale\n",
    "])\n",
    "\n",
    "# Categorical columns and associated transformers\n",
    "cat_hot_feat = ['mos_gender']\n",
    "cat_hot_transformer = Pipeline(steps=[\n",
    "    ('onehot', pp.OneHotEncoder())     # output from Ordinal becomes input to OneHot\n",
    "])\n",
    "\n",
    "# preprocessing pipeline (put them together)\n",
    "preproc = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_feat),\n",
    "        ('hot_cat', cat_hot_transformer, cat_hot_feat),\n",
    "    ])\n",
    "\n",
    "pl2 = Pipeline(steps=[('preprocessor', preproc), ('regressor', LogisticRegression())])\n",
    "\n",
    "# Fit the model into the pipeline\n",
    "pl2.fit(X,y)\n",
    "y_pred = pl2.predict(X)\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "\n",
    "# R^2 \n",
    "print(pl2.score(X, y)) # A Slightly better prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linxi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\linxi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "         Captain       0.00      0.00      0.00       109\n",
      "Deputy Inspector       0.00      0.00      0.00        75\n",
      "       Detective       0.00      0.00      0.00      2584\n",
      "       Inspector       0.00      0.00      0.00        23\n",
      "      Lieutenant       0.17      0.01      0.02      1018\n",
      "  Police Officer       0.72      0.95      0.82     18690\n",
      "        Sergeant       0.29      0.16      0.20      4849\n",
      "\n",
      "        accuracy                           0.68     27348\n",
      "       macro avg       0.17      0.16      0.15     27348\n",
      "    weighted avg       0.55      0.68      0.60     27348\n",
      "\n",
      "0.6774901272487933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linxi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\linxi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X, y = data[['mos_ethnicity','mos_gender','mos_age_incident']], data['rank_incident']\n",
    "# Numeric columns and associated transformers\n",
    "num_feat = ['mos_age_incident']\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('scaler', pp.StandardScaler())   # z-scale\n",
    "])\n",
    "\n",
    "# Categorical columns and associated transformers\n",
    "cat_hot_feat = ['mos_gender']\n",
    "cat_hot_transformer = Pipeline(steps=[\n",
    "    ('onehot', pp.OneHotEncoder())     # output from Ordinal becomes input to OneHot\n",
    "])\n",
    "\n",
    "# Categorical columns and associated transformers\n",
    "cat_feat = ['mos_ethnicity']\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('ordin', pp.OrdinalEncoder())     # output from Ordinal becomes input to OneHot\n",
    "])\n",
    "\n",
    "# preprocessing pipeline (put them together)\n",
    "preproc = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_feat),\n",
    "        ('hot_cat', cat_hot_transformer, cat_hot_feat),\n",
    "        ('cat', cat_transformer, cat_feat)\n",
    "    ])\n",
    "\n",
    "pl3 = Pipeline(steps=[('preprocessor', preproc), ('regressor', LogisticRegression())])\n",
    "\n",
    "# Fit the model into the pipeline\n",
    "pl3.fit(X,y)\n",
    "y_pred = pl3.predict(X)\n",
    "print(metrics.classification_report(y, y_pred))\n",
    "\n",
    "# R^2 \n",
    "print(pl3.score(X, y)) # A even slightly better prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data[['mos_ethnicity','mos_gender','mos_age_incident','rank_now']], data['rank_incident']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric columns and associated transformers\n",
    "num_feat = ['mos_age_incident']\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('scaler', pp.StandardScaler())   # z-scale\n",
    "])\n",
    "\n",
    "# Categorical columns and associated transformers\n",
    "cat_hot_feat = ['mos_gender']\n",
    "cat_hot_transformer = Pipeline(steps=[\n",
    "    ('onehot', pp.OneHotEncoder())     # output from Ordinal becomes input to OneHot\n",
    "])\n",
    "\n",
    "# Categorical columns and associated transformers\n",
    "cat_feat = ['mos_ethnicity', 'rank_now']\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('ordin', pp.OrdinalEncoder())     # output from Ordinal becomes input to OneHot\n",
    "])\n",
    "\n",
    "# preprocessing pipeline (put them together)\n",
    "preproc = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_feat),\n",
    "        ('hot_cat', cat_hot_transformer, cat_hot_feat),\n",
    "        ('cat', cat_transformer, cat_feat)\n",
    "    ])\n",
    "\n",
    "pl4 = Pipeline(steps=[('preprocessor', preproc), ('regressor', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linxi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['mos_age_incident']),\n",
       "                                                 ('hot_cat',\n",
       "                                                  Pipeline(steps=[('onehot',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['mos_gender']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('ordin',\n",
       "                                                                   OrdinalEncoder())]),\n",
       "                                                  ['mos_ethnicity',\n",
       "                                                   'rank_now'])])),\n",
       "                ('regressor', LogisticRegression())])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl4.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Police Officer', 'Police Officer', 'Police Officer', ...,\n",
       "       'Police Officer', 'Police Officer', 'Police Officer'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pl4.predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linxi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "         Captain       0.61      0.39      0.47       109\n",
      "Deputy Inspector       0.30      0.09      0.14        75\n",
      "       Detective       0.46      0.28      0.35      2584\n",
      "       Inspector       0.00      0.00      0.00        23\n",
      "      Lieutenant       0.28      0.03      0.06      1018\n",
      "  Police Officer       0.74      0.93      0.83     18690\n",
      "        Sergeant       0.52      0.23      0.32      4849\n",
      "\n",
      "        accuracy                           0.71     27348\n",
      "       macro avg       0.42      0.28      0.31     27348\n",
      "    weighted avg       0.66      0.71      0.66     27348\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linxi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\linxi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7076203013017406"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R^2 \n",
    "pl4.score(X, y) # Best prediction among the all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall from the final model that the X,y is:\n",
    "\n",
    "X,y = data[['mos_ethnicity','mos_gender','mos_age_incident','rank_now']], data['rank_incident']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training and the test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mos_ethnicity</th>\n",
       "      <th>mos_gender</th>\n",
       "      <th>mos_age_incident</th>\n",
       "      <th>rank_now</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27319</th>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>28</td>\n",
       "      <td>Sergeant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18133</th>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>34</td>\n",
       "      <td>Detective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4287</th>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>44</td>\n",
       "      <td>Sergeant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22056</th>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>41</td>\n",
       "      <td>Sergeant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30545</th>\n",
       "      <td>Hispanic</td>\n",
       "      <td>M</td>\n",
       "      <td>37</td>\n",
       "      <td>Police Officer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mos_ethnicity mos_gender  mos_age_incident        rank_now\n",
       "27319         White          M                28        Sergeant\n",
       "18133         White          M                34       Detective\n",
       "4287          White          M                44        Sergeant\n",
       "22056         White          M                41        Sergeant\n",
       "30545      Hispanic          M                37  Police Officer"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First 5 rows of the train data after splitting\n",
    "display(X_train.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mos_ethnicity</th>\n",
       "      <th>mos_gender</th>\n",
       "      <th>mos_age_incident</th>\n",
       "      <th>rank_now</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18946</th>\n",
       "      <td>Black</td>\n",
       "      <td>M</td>\n",
       "      <td>36</td>\n",
       "      <td>Detective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4815</th>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>38</td>\n",
       "      <td>Detective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6235</th>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>27</td>\n",
       "      <td>Sergeant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31397</th>\n",
       "      <td>White</td>\n",
       "      <td>F</td>\n",
       "      <td>39</td>\n",
       "      <td>Lieutenant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31224</th>\n",
       "      <td>Hispanic</td>\n",
       "      <td>M</td>\n",
       "      <td>29</td>\n",
       "      <td>Police Officer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mos_ethnicity mos_gender  mos_age_incident        rank_now\n",
       "18946         Black          M                36       Detective\n",
       "4815          White          M                38       Detective\n",
       "6235          White          M                27        Sergeant\n",
       "31397         White          F                39      Lieutenant\n",
       "31224      Hispanic          M                29  Police Officer"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_test.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27319    Police Officer\n",
       "18133    Police Officer\n",
       "4287           Sergeant\n",
       "22056          Sergeant\n",
       "30545    Police Officer\n",
       "Name: rank_incident, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(y_train.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18946         Detective\n",
       "4815     Police Officer\n",
       "6235     Police Officer\n",
       "31397        Lieutenant\n",
       "31224    Police Officer\n",
       "Name: rank_incident, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(y_test.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "         Captain       0.40      0.65      0.50        55\n",
      "Deputy Inspector       0.10      0.29      0.14        17\n",
      "       Detective       0.28      0.45      0.35      1103\n",
      "       Inspector       0.00      0.00      0.00         0\n",
      "      Lieutenant       0.03      0.32      0.06        75\n",
      "  Police Officer       0.93      0.74      0.83     16377\n",
      "        Sergeant       0.23      0.52      0.32      1516\n",
      "\n",
      "        accuracy                           0.71     19143\n",
      "       macro avg       0.28      0.43      0.31     19143\n",
      "    weighted avg       0.83      0.71      0.76     19143\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linxi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\linxi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\linxi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pred_train = pl4.predict(X_train)\n",
    "print(metrics.classification_report(pred_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "         Captain       0.30      0.43      0.35        14\n",
      "Deputy Inspector       0.09      0.33      0.14         6\n",
      "       Detective       0.28      0.47      0.35       468\n",
      "       Inspector       0.00      0.00      0.00         0\n",
      "      Lieutenant       0.03      0.22      0.05        41\n",
      "  Police Officer       0.93      0.74      0.83      7067\n",
      "        Sergeant       0.22      0.52      0.31       609\n",
      "\n",
      "        accuracy                           0.71      8205\n",
      "       macro avg       0.26      0.39      0.29      8205\n",
      "    weighted avg       0.84      0.71      0.76      8205\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linxi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\linxi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\linxi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pred_test = pl4.predict(X_test)\n",
    "print(metrics.classification_report(pred_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
